#!/usr/bin/env python3
import os
import re
import json
import base64
import tempfile
import zlib
import random
from html.parser import HTMLParser

import requests
import yaml
import markdown

# ================= é…ç½® =================

CONFIG_FILE = "config/wechat-credentials.local.md"
WECHAT_API_BASE = "https://api.weixin.qq.com/cgi-bin"
UNSPLASH_API_BASE = "https://api.unsplash.com"

# ä¸­æ–‡åœç”¨è¯ï¼ˆç”¨äºå…³é”®è¯æå–ï¼‰
CHINESE_STOPWORDS = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™', 'é‚£', 'ä»€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'æ€ä¹ˆ', 'æ€æ ·'}

# ä¸­æ–‡æŠ€æœ¯è¯æ±‡åˆ°è‹±æ–‡çš„æ˜ å°„ï¼ˆæå‡ Unsplash æœç´¢æ•ˆæœï¼‰
KEYWORD_TRANSLATIONS = {
    'è®¤è¯': 'authentication', 'ç™»å½•': 'login', 'å®‰å…¨': 'security',
    'æ¶æ„': 'architecture', 'è®¾è®¡': 'design', 'ç³»ç»Ÿ': 'system',
    'æ•°æ®': 'data', 'åˆ†æ': 'analytics', 'äººå·¥æ™ºèƒ½': 'artificial intelligence',
    'æœºå™¨å­¦ä¹ ': 'machine learning', 'æ·±åº¦å­¦ä¹ ': 'deep learning',
    'ç¼–ç¨‹': 'programming', 'å¼€å‘': 'development', 'ä»£ç ': 'code',
    'ç½‘ç»œ': 'network', 'äº‘è®¡ç®—': 'cloud computing', 'æœåŠ¡å™¨': 'server',
    'æ•°æ®åº“': 'database', 'æ¥å£': 'API', 'å‰ç«¯': 'frontend',
    'åç«¯': 'backend', 'ç§»åŠ¨': 'mobile', 'åº”ç”¨': 'application',
    'ç”¨æˆ·': 'user', 'äº§å“': 'product', 'é¡¹ç›®': 'project',
    'å›¢é˜Ÿ': 'team', 'ç®¡ç†': 'management', 'æ•ˆç‡': 'efficiency',
    'åˆ›æ–°': 'innovation', 'æŠ€æœ¯': 'technology', 'è§£å†³æ–¹æ¡ˆ': 'solution',
    'ç»Ÿä¸€': 'unified', 'ä¸­å¿ƒ': 'center', 'å¹³å°': 'platform',
    'é›†æˆ': 'integration', 'é—¨æˆ·': 'portal', 'å•ç‚¹ç™»å½•': 'SSO',
}

# Unsplash é€šç”¨åˆ†ç±»ï¼ˆç¿»è¯‘å¤±è´¥æ—¶çš„é™çº§é€‰é¡¹ï¼‰
UNSPLASH_FALLBACK_CATEGORIES = [
    'technology', 'business', 'abstract', 'minimal',
    'workspace', 'nature', 'architecture', 'gradient'
]

# Admonition SVG å›¾æ ‡
ADMONITION_ICONS = {
    'pencil': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><path d="M17 3a2.85 2.83 0 1 1 4 4L7.5 20.5 2 22l1.5-5.5Z"></path><path d="m15 5 4 4"></path></svg>',
    'clipboard-list': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><rect x="8" y="2" width="8" height="4" rx="1" ry="1"></rect><path d="M16 4h2a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h2"></path><path d="M12 11h4"></path><path d="M12 16h4"></path><path d="M8 11h.01"></path><path d="M8 16h.01"></path></svg>',
    'info': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg>',
    'check-circle-2': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><circle cx="12" cy="12" r="10"></circle><path d="m9 12 2 2 4-4"></path></svg>',
    'flame': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><path d="M8.5 14.5A2.5 2.5 0 0 0 11 12c0-1.38-.5-2-1-3-1.072-2.143-.224-4.054 2-6 .5 2.5 2 4.9 4 6.5 2 1.6 3 3.5 3 5.5a7 7 0 1 1-14 0c0-1.153.433-2.294 1-3a2.5 2.5 0 0 0 2.5 2.5z"></path></svg>',
    'check': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><path d="M20 6 9 17l-5-5"></path></svg>',
    'help-circle': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><circle cx="12" cy="12" r="10"></circle><path d="M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3"></path><path d="M12 17h.01"></path></svg>',
    'alert-triangle': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><path d="m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3Z"></path><path d="M12 9v4"></path><path d="M12 17h.01"></path></svg>',
    'x': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg>',
    'zap': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><polygon points="13 2 3 14 12 14 11 22 21 10 12 10 13 2"></polygon></svg>',
    'bug': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><path d="m8 2 1.88 1.88"></path><path d="M14.12 3.88 16 2"></path><path d="M9 7.13v-1a3.003 3.003 0 1 1 6 0v1"></path><path d="M12 20c-3.3 0-6-2.7-6-6v-3a4 4 0 0 1 4-4h4a4 4 0 0 1 4 4v3c0 3.3-2.7 6-6 6"></path><path d="M12 20v-9"></path><path d="M6.53 9C4.6 8.8 3 7.1 3 5"></path><path d="M6 13H2"></path><path d="M3 21c0-2.1 1.7-3.9 3.8-4"></path><path d="M20.97 5c0 2.1-1.6 3.8-3.5 4"></path><path d="M22 13h-4"></path><path d="M17.2 17c2.1.1 3.8 1.9 3.8 4"></path></svg>',
    'list': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><line x1="8" y1="6" x2="21" y2="6"></line><line x1="8" y1="12" x2="21" y2="12"></line><line x1="8" y1="18" x2="21" y2="18"></line><line x1="3" y1="6" x2="3.01" y2="6"></line><line x1="3" y1="12" x2="3.01" y2="12"></line><line x1="3" y1="18" x2="3.01" y2="18"></line></svg>',
    'quote': '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="callout-icon"><path d="M3 21c3 0 7-1 7-8V5c0-1.25-.756-2.017-2-2H4c-1.25 0-2 .75-2 1.972V11c0 1.25.75 2 2 2 1 0 1 0 1 1v1c0 1-1 2-2 2s-1 .008-1 1.031V20c0 1 0 1 1 1z"></path><path d="M15 21c3 0 7-1 7-8V5c0-1.25-.757-2.017-2-h-4c-1.25 0-2 .75-2 1.972V11c0 1.25.75 2 2 2h.75c0 2.25.25 4-2.75 4v3c0 1 0 1 1 1z"></path></svg>'
}

ADMONITION_TYPES = {
    'note': {'color': '#448aff', 'bg': 'rgba(68, 138, 255, 0.1)', 'icon': 'pencil'},
    'abstract': {'color': '#00bfa5', 'bg': 'rgba(0, 191, 165, 0.1)', 'icon': 'clipboard-list'},
    'info': {'color': '#448aff', 'bg': 'rgba(68, 138, 255, 0.1)', 'icon': 'info'},
    'todo': {'color': '#448aff', 'bg': 'rgba(68, 138, 255, 0.1)', 'icon': 'check-circle-2'},
    'tip': {'color': '#00bfa5', 'bg': 'rgba(0, 191, 165, 0.1)', 'icon': 'flame'},
    'success': {'color': '#00c853', 'bg': 'rgba(0, 200, 83, 0.1)', 'icon': 'check'},
    'question': {'color': '#ffab00', 'bg': 'rgba(255, 171, 0, 0.1)', 'icon': 'help-circle'},
    'warning': {'color': '#ff9100', 'bg': 'rgba(255, 171, 0, 0.1)', 'icon': 'alert-triangle'},
    'failure': {'color': '#ff5252', 'bg': 'rgba(255, 82, 82, 0.1)', 'icon': 'x'},
    'danger': {'color': '#ff5252', 'bg': 'rgba(255, 82, 82, 0.1)', 'icon': 'zap'},
    'bug': {'color': '#ff5252', 'bg': 'rgba(255, 82, 82, 0.1)', 'icon': 'bug'},
    'example': {'color': '#7c4dff', 'bg': 'rgba(124, 77, 255, 0.1)', 'icon': 'list'},
    'quote': {'color': '#9e9e9e', 'bg': 'rgba(158, 158, 158, 0.1)', 'icon': 'quote'}
}

ADMONITION_ALIASES = {
    'summary': 'abstract', 'tldr': 'abstract',
    'hint': 'tip', 'important': 'tip',
    'check': 'success', 'done': 'success',
    'help': 'question', 'faq': 'question',
    'caution': 'warning', 'attention': 'warning',
    'fail': 'failure', 'missing': 'failure',
    'error': 'danger', 'cite': 'quote'
}

# å†…è”æ ·å¼å¸¸é‡
STYLES = {
    'h1': 'font-size: 22px; font-weight: bold; margin: 20px 0 10px; text-align: center; padding-bottom: 5px; border-bottom: 2px solid #db4c3f;',
    'h2': 'font-size: 20px; font-weight: bold; margin: 25px 0 15px; padding: 5px 10px; border-left: 5px solid #db4c3f; border-bottom: 1px dashed #db4c3f; line-height: 1.5;',
    'h3': 'font-size: 18px; font-weight: bold; margin: 22px 0 12px; padding: 5px 10px; border-left: 5px solid #db4c3f; border-bottom: 1px dashed #db4c3f; line-height: 1.5;',
    'h4': 'font-size: 16px; font-weight: bold; margin: 20px 0 10px; padding: 4px 8px; border-left: 4px solid #db4c3f; line-height: 1.5;',
    'strong': 'color: #db4c3f; font-weight: bold;',
    'th': 'font-weight: 600; color: #db4c3f; padding: 6px 13px; border: 1px solid #e6dec5; background: #f7f1e3;',
    'td': 'padding: 6px 13px; border: 1px solid #e6dec5;',
    'hr': 'border: 0; height: 1px; background-image: linear-gradient(to right, rgba(219, 76, 63, 0), rgba(219, 76, 63, 1), rgba(219, 76, 63, 0)); margin: 40px 0;',
    'list_container': "list-style: none; margin: 0em 8px 1.5em; padding: 0px; text-align: left; line-height: 1.75; font-family: 'PingFang SC', -apple-system-font, BlinkMacSystemFont, 'Helvetica Neue', 'Hiragino Sans GB', 'Microsoft YaHei UI', 'Microsoft YaHei', Arial, sans-serif; font-size: 15px; color: rgb(63, 63, 63);",
    'list_item': "margin: 0.5em 0px; padding: 0px; text-align: left; line-height: 1.75; font-family: 'PingFang SC', -apple-system-font, BlinkMacSystemFont, 'Helvetica Neue', 'Hiragino Sans GB', 'Microsoft YaHei UI', 'Microsoft YaHei', Arial, sans-serif; font-size: 15px; color: rgb(63, 63, 63);",
    'pre': 'background: #f6f8fa; border: 1px solid #e1e4e8; border-radius: 6px; padding: 16px; margin: 16px 0; line-height: 1.6; font-family: Consolas, Monaco, "Andale Mono", "Ubuntu Mono", monospace; font-size: 13px; color: #333; white-space: pre-wrap; word-break: break-all; overflow-x: auto;',
    'inline_code': 'background: #f0f0f0; color: #db4c3f; padding: 2px 4px; border-radius: 3px; font-family: Consolas, Monaco, monospace; font-size: 14px; margin: 0 2px;',
}

BASIC_STYLE = """
<style>
  #nice { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; font-size: 16px; line-height: 1.6; color: #333; word-wrap: break-word; }
  #nice h1 { font-size: 22px; font-weight: bold; margin: 20px 0 10px; text-align: center; padding-bottom: 5px; border-bottom: 2px solid #db4c3f; }
  #nice h2 { font-size: 20px; font-weight: bold; margin: 18px 0 10px; padding: 5px 10px; border-left: 5px solid #db4c3f; border-bottom: 1px dashed #db4c3f; background: #fff5f5; line-height: 1.5; }
  #nice h3 { font-size: 18px; font-weight: bold; margin: 16px 0 8px; }
  #nice p { margin-bottom: 15px; text-align: justify; }
  #nice code { background-color: rgba(27,31,35,.05); border-radius: 3px; font-size: 85%; margin: 0; padding: .2em .4em; font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace; }
  #nice pre { background: #f6f8fa; border-radius: 4px; padding: 16px; overflow: auto; line-height: 1.45; }
  #nice pre code { background: transparent; padding: 0; white-space: pre; }
  #nice blockquote { margin: 0 0 16px; padding: 0 1em; color: #6a737d; border-left: .25em solid #db4c3f; background-color: #fff5f5; }
  #nice img { max-width: 100%; border-radius: 4px; display: block; margin: 20px auto; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
  #nice ul, #nice ol { padding-left: 2em; margin-bottom: 16px; }
  #nice li { margin-bottom: 4px; }
  #nice table { display: block; width: 100%; overflow: auto; margin-bottom: 16px; border-spacing: 0; border-collapse: collapse; }
  #nice tr { background-color: #fff; border-top: 1px solid #fabec9; }
  #nice tr:nth-child(2n) { background-color: #fff5f5; }
  #nice th, #nice td { padding: 6px 13px; border: 1px solid #fabec9; }
  #nice th { font-weight: 600; color: #db4c3f; background-color: #fff5f5; }
  #nice strong { color: #db4c3f; }
  #nice hr { border: none; border-top: 1px dashed #db4c3f; margin: 30px 0; }
  .callout-icon svg { width: 20px; height: 20px; vertical-align: middle; }
  .footnotes { font-size: 14px; color: #666; margin-top: 40px; padding-top: 20px; border-top: 1px dashed #db4c3f; }
  .footnote-item { margin-bottom: 10px; }
</style>
"""


# ================= å·¥å…·å‡½æ•° =================

def load_config() -> dict:
    if not os.path.exists(CONFIG_FILE):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {CONFIG_FILE} ä¸å­˜åœ¨")
    with open(CONFIG_FILE, 'r') as f:
        content = f.read()
    match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
    return yaml.safe_load(match.group(1)) if match else {}


def get_access_token(config: dict) -> str:
    if config.get('access_token'):
        return config['access_token']

    resp = requests.get(f"{WECHAT_API_BASE}/token", params={
        "grant_type": "client_credential",
        "appid": config['appid'],
        "secret": config['secret']
    })
    data = resp.json()

    if 'access_token' not in data:
        raise Exception(f"è·å– Token å¤±è´¥: {data}")
    return data['access_token']


def upload_image(token: str, image_path_or_url: str) -> str | None:
    """ä¸Šä¼ å›¾ç‰‡åˆ°å¾®ä¿¡ï¼Œæ”¯æŒæœ¬åœ°è·¯å¾„å’Œè¿œç¨‹ URL"""
    url = f"{WECHAT_API_BASE}/media/uploadimg?access_token={token}"

    if image_path_or_url.startswith(('http://', 'https://')):
        files = _download_image_for_upload(image_path_or_url)
        if not files:
            return None
    else:
        if not os.path.exists(image_path_or_url):
            print(f"æœ¬åœ°å›¾ç‰‡ä¸å­˜åœ¨: {image_path_or_url}")
            return None
        files = {'media': open(image_path_or_url, 'rb')}

    data = requests.post(url, files=files).json()
    if 'url' not in data:
        print(f"ä¸Šä¼ å›¾ç‰‡å¤±è´¥: {data}")
        return None
    return data['url']


def _download_image_for_upload(image_url: str) -> dict | None:
    """ä¸‹è½½è¿œç¨‹å›¾ç‰‡å¹¶å‡†å¤‡ä¸Šä¼ """
    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'}

    try:
        resp = requests.get(image_url, headers=headers, timeout=30)
        if resp.status_code != 200 or not resp.content:
            print(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status_code}")
            return None

        content_type = resp.headers.get('Content-Type', 'image/jpeg').lower()
        ext_map = {
            'image/png': '.png', 'image/jpeg': '.jpg', 'image/jpg': '.jpg',
            'image/gif': '.gif', 'image/webp': '.webp'
        }
        ext = ext_map.get(content_type, '.jpg')

        return {'media': (f'image{ext}', resp.content, content_type)}
    except Exception as e:
        print(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
        return None


# ================= è‡ªåŠ¨å°é¢åŠŸèƒ½ =================

def translate_to_english(text: str) -> str | None:
    """å°†ä¸­æ–‡ç¿»è¯‘ä¸ºè‹±æ–‡ï¼Œä½¿ç”¨å¤šå±‚é™çº§ç­–ç•¥"""
    # 1. å…ˆæŸ¥ç¡¬ç¼–ç å­—å…¸ï¼ˆå¿«é€Ÿç¼“å­˜ï¼‰
    if text in KEYWORD_TRANSLATIONS:
        return KEYWORD_TRANSLATIONS[text]

    # 2. å°è¯•åœ¨çº¿ç¿»è¯‘ï¼ˆtranslators åº“ï¼Œä¼˜å…ˆ Googleï¼‰
    try:
        import translators as ts
        result = ts.translate_text(text, from_language='zh', to_language='en', translator='google')
        if result and result != text:
            return result
    except Exception:
        pass

    return None  # ç¿»è¯‘å¤±è´¥


def extract_keywords(title: str, digest: str = "") -> list[str]:
    """ä»æ ‡é¢˜å’Œæ‘˜è¦æå–å…³é”®è¯ï¼Œè‡ªåŠ¨ç¿»è¯‘ä¸ºè‹±æ–‡"""
    text = f"{title} {digest}"

    # 1. æå–è‹±æ–‡å•è¯
    english_words = re.findall(r'[a-zA-Z]{3,}', text)

    # 2. æå–ä¸­æ–‡å¹¶ç¿»è¯‘
    chinese_text = re.sub(r'[a-zA-Z0-9\s\W]+', '', text)
    translated = []
    if chinese_text:
        result = translate_to_english(chinese_text[:20])
        if result:
            translated = result.split()[:3]

    # 3. åˆå¹¶å»é‡
    keywords = []
    seen = set()
    for word in english_words + translated:
        word_lower = word.lower()
        if word_lower not in seen and len(word) >= 2:
            seen.add(word_lower)
            keywords.append(word)
            if len(keywords) >= 5:
                break

    # 4. å¦‚æœæ²¡æœ‰å…³é”®è¯ï¼Œä»é€šç”¨åˆ†ç±»éšæœºé€‰ä¸€ä¸ª
    if not keywords:
        keywords = [random.choice(UNSPLASH_FALLBACK_CATEGORIES)]

    return keywords


def _search_unsplash(access_key: str, query: str) -> str | None:
    """æ‰§è¡Œå•æ¬¡ Unsplash æœç´¢"""
    try:
        resp = requests.get(
            f"{UNSPLASH_API_BASE}/search/photos",
            params={
                'query': query,
                'orientation': 'landscape',  # æ¨ªå‘å›¾ç‰‡é€‚åˆå¾®ä¿¡å°é¢
                'per_page': 1
            },
            headers={'Authorization': f'Client-ID {access_key}'},
            timeout=10
        )

        if resp.status_code == 403:
            print("  Unsplash API é™æµï¼Œè·³è¿‡è‡ªåŠ¨å°é¢")
            return None

        data = resp.json()
        if data.get('results'):
            # ä½¿ç”¨ regular å°ºå¯¸ï¼ˆ1080px å®½åº¦ï¼Œé€‚åˆå¾®ä¿¡ï¼‰
            return data['results'][0]['urls'].get('regular')
        return None
    except Exception as e:
        print(f"  Unsplash æœç´¢å¤±è´¥: {e}")
        return None


def search_unsplash_cover(access_key: str, keywords: list[str]) -> str | None:
    """ä» Unsplash æœç´¢æ¨ªå‘å°é¢å›¾ç‰‡ï¼Œæ”¯æŒé™çº§åˆ°é€šç”¨åˆ†ç±»"""
    if not access_key:
        return None

    # 1. å°è¯•ç”¨å…³é”®è¯æœç´¢
    query = ' '.join(keywords[:3])
    print(f"  æœç´¢ Unsplash: {query}")
    image_url = _search_unsplash(access_key, query)
    if image_url:
        print(f"  âœ“ æ‰¾åˆ°åŒ¹é…å›¾ç‰‡")
        return image_url

    # 2. æœªæ‰¾åˆ°ï¼Œé™çº§åˆ°é€šç”¨åˆ†ç±»éšæœºæœç´¢
    print(f"  æœªæ‰¾åˆ°åŒ¹é…å›¾ç‰‡ï¼Œå°è¯•é€šç”¨åˆ†ç±»...")
    fallback_category = random.choice(UNSPLASH_FALLBACK_CATEGORIES)
    print(f"  æœç´¢ Unsplash: {fallback_category}")
    image_url = _search_unsplash(access_key, fallback_category)
    if image_url:
        print(f"  âœ“ ä» '{fallback_category}' åˆ†ç±»æ‰¾åˆ°å›¾ç‰‡")
        return image_url

    print(f"  é€šç”¨åˆ†ç±»ä¹Ÿæœªæ‰¾åˆ°å›¾ç‰‡")
    return None


def download_image_to_temp(image_url: str) -> str | None:
    """ä¸‹è½½å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'}
        resp = requests.get(image_url, headers=headers, timeout=30)

        if resp.status_code != 200:
            return None

        with tempfile.NamedTemporaryFile(mode='wb', suffix='.jpg', delete=False) as f:
            f.write(resp.content)
            return f.name
    except Exception as e:
        print(f"  ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
        return None


def upload_cover_material(token: str, image_path: str) -> str | None:
    """ä¸Šä¼ å°é¢å›¾ç‰‡ä¸ºå¾®ä¿¡æ°¸ä¹…ç´ æï¼Œè¿”å› media_id"""
    url = f"{WECHAT_API_BASE}/material/add_material?access_token={token}&type=image"

    try:
        with open(image_path, 'rb') as f:
            files = {'media': ('cover.jpg', f, 'image/jpeg')}
            resp = requests.post(url, files=files, timeout=30)

        data = resp.json()
        if 'media_id' in data:
            print(f"  âœ“ å°é¢ä¸Šä¼ æˆåŠŸ: {data['media_id'][:20]}...")
            return data['media_id']

        print(f"  å°é¢ä¸Šä¼ å¤±è´¥: {data}")
        return None
    except Exception as e:
        print(f"  å°é¢ä¸Šä¼ å¤±è´¥: {e}")
        return None


def get_auto_cover(config: dict, token: str, title: str, digest: str = "") -> str | None:
    """è‡ªåŠ¨è·å–å°é¢å›¾ç‰‡çš„ media_id"""
    if not config.get('enable_auto_cover', False):
        return None

    access_key = config.get('unsplash_access_key', '')
    if not access_key:
        print("  æœªé…ç½® Unsplash API Keyï¼Œè·³è¿‡è‡ªåŠ¨å°é¢")
        return None

    print("\nğŸ¨ è‡ªåŠ¨æœç´¢å°é¢å›¾ç‰‡...")

    # 1. æå–å…³é”®è¯
    keywords = extract_keywords(title, digest)
    print(f"  å…³é”®è¯: {', '.join(keywords)}")

    # 2. æœç´¢ Unsplash
    image_url = search_unsplash_cover(access_key, keywords)
    if not image_url:
        return None

    # 3. ä¸‹è½½å›¾ç‰‡
    temp_path = download_image_to_temp(image_url)
    if not temp_path:
        return None

    # 4. ä¸Šä¼ åˆ°å¾®ä¿¡
    media_id = upload_cover_material(token, temp_path)

    # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try:
        os.unlink(temp_path)
    except:
        pass

    return media_id


# ================= Mermaid æ¸²æŸ“ =================

def render_mermaid_with_playwright(mermaid_code: str) -> str | None:
    """ä½¿ç”¨ Playwright æ¸²æŸ“ Mermaid å›¾è¡¨"""
    try:
        import playwright.sync_api as pw
    except ImportError:
        print("è­¦å‘Š: playwright åº“æœªå®‰è£…")
        return None

    html_content = _build_mermaid_html(mermaid_code)

    try:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8') as f:
            f.write(html_content)
            html_path = f.name

        output_path = html_path.replace('.html', '.png')

        with pw.sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page(viewport={'width': 1000, 'height': 800}, device_scale_factor=2)
            page.goto(f'file://{html_path}')
            page.wait_for_timeout(3000)

            element = page.query_selector('.mermaid svg')
            if element:
                element.screenshot(path=output_path, scale='device', omit_background=True)
            else:
                page.screenshot(path=output_path, full_page=True)
            browser.close()

        os.unlink(html_path)
        return output_path
    except Exception as e:
        print(f"Playwright æ¸²æŸ“å¤±è´¥: {e}")
        return None


def _build_mermaid_html(mermaid_code: str) -> str:
    """æ„å»º Mermaid æ¸²æŸ“ç”¨çš„ HTML"""
    return f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
        body {{ margin: 0; padding: 80px; background: white; display: inline-block; }}
        #mermaid-container {{ background: white; }}
        .mermaid text {{ font-size: 16px !important; font-family: -apple-system, BlinkMacSystemFont, sans-serif !important; }}
        .mermaid .edgeLabel {{ font-size: 14px !important; background-color: white !important; padding: 4px !important; }}
        .mermaid text.sequenceNumber, .mermaid .sequenceNumber text {{ fill: #fff !important; stroke: none !important; }}
    </style>
</head>
<body>
    <div id="mermaid-container">
        <pre class="mermaid">{mermaid_code}</pre>
    </div>
    <script>
        mermaid.initialize({{
            startOnLoad: true,
            theme: 'default',
            themeVariables: {{ fontSize: '16px', fontFamily: '-apple-system, BlinkMacSystemFont, sans-serif' }},
            flowchart: {{ htmlLabels: true, curve: 'basis', padding: 40 }},
            sequence: {{ showSequenceNumbers: true, fontSize: 16 }}
        }});
    </script>
</body>
</html>"""


def render_mermaid_with_kroki(mermaid_code: str) -> str | None:
    """ä½¿ç”¨ Kroki.io API æ¸²æŸ“ Mermaidï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    try:
        compressed = zlib.compress(mermaid_code.encode('utf-8'), level=9)
        encoded = base64.urlsafe_b64encode(compressed).decode('utf-8')
        kroki_url = f"https://kroki.io/mermaid/png/{encoded}"

        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'}
        response = requests.get(kroki_url, headers=headers, timeout=15)

        if response.status_code == 200 and response.content:
            with tempfile.NamedTemporaryFile(mode='wb', suffix='.png', delete=False) as f:
                f.write(response.content)
                return f.name

        print(f"Kroki.io è¿”å›é”™è¯¯: {response.status_code}")
        return None
    except Exception as e:
        print(f"Kroki.io æ¸²æŸ“å¤±è´¥: {e}")
        return None


def render_mermaid_locally(mermaid_code: str) -> str | None:
    """å¤šå±‚é™çº§ç­–ç•¥æ¸²æŸ“ Mermaid: Kroki.io -> Playwright -> None"""
    print("  [1/2] å°è¯•ä½¿ç”¨ Kroki.io åœ¨çº¿æ¸²æŸ“...")
    result = render_mermaid_with_kroki(mermaid_code)
    if result:
        print("  âœ“ Kroki.io æ¸²æŸ“æˆåŠŸ")
        return result

    print("  [2/2] å°è¯•ä½¿ç”¨ Playwright æœ¬åœ°æ¸²æŸ“...")
    result = render_mermaid_with_playwright(mermaid_code)
    if result:
        print("  âœ“ Playwright æ¸²æŸ“æˆåŠŸ")
        return result

    print("  æ‰€æœ‰æ¸²æŸ“æ–¹æ¡ˆå¤±è´¥ï¼Œå°†æ˜¾ç¤ºä¸ºä»£ç å—")
    return None


# ================= Markdown é¢„å¤„ç† =================

def process_mermaid(content: str) -> str:
    """å°† Mermaid ä»£ç å—è½¬æ¢ä¸ºå›¾ç‰‡æˆ–é™çº§ä¸ºä»£ç å—"""
    def repl(m):
        code = m.group(1).strip()
        print("\nå¤„ç† Mermaid å›¾è¡¨...")

        local_path = render_mermaid_locally(code)
        if local_path:
            return f'![MERMAID_DIAGRAM]({local_path})'

        # é™çº§ä¸ºæ ¼å¼åŒ–ä»£ç å—
        escaped = code.replace('<', '&lt;').replace('>', '&gt;')
        return f'''
<section class="mermaid-fallback" style="background: #f5f7fa; padding: 16px; border-radius: 8px; margin: 20px 0; border-left: 4px solid #909399;">
  <p style="color: #606266; font-size: 14px; margin: 0 0 12px; font-weight: 600;">ğŸ“Š æµç¨‹å›¾ (Mermaid)</p>
  <pre style="background: #fff; padding: 12px; border-radius: 4px; overflow-x: auto; margin: 0; font-family: Consolas, Monaco, monospace; font-size: 13px; line-height: 1.5; color: #303133;"><code>{escaped}</code></pre>
  <p style="color: #909399; font-size: 12px; margin: 12px 0 0; font-style: italic;">æç¤º: å›¾è¡¨æ¸²æŸ“æš‚æ—¶ä¸å¯ç”¨ï¼Œå·²æ˜¾ç¤ºåŸå§‹ä»£ç </p>
</section>'''

    return re.sub(r'```mermaid\s*\n([\s\S]*?)```', repl, content)


def process_admonitions(content: str) -> str:
    """å°† Admonition ä»£ç å—è½¬æ¢ä¸º HTML"""
    def repl(m):
        ad_type = ADMONITION_ALIASES.get(m.group(1).lower(), m.group(1).lower())
        title = (m.group(2) or '').strip() or ad_type.capitalize()
        body = m.group(3)

        config = ADMONITION_TYPES.get(ad_type, ADMONITION_TYPES['note'])
        icon_svg = ADMONITION_ICONS.get(config['icon'], ADMONITION_ICONS['pencil'])
        body_html = markdown.markdown(body, extensions=['fenced_code', 'tables'])

        return f'''
<section class="admonition" style="border-radius: 4px; margin: 16px 0; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
  <section class="admonition-title" style="display: flex; align-items: center; padding: 8px 12px; background: {config['bg']};">
    <span style="color: {config['color']}; margin-right: 8px; display: flex; align-items: center;">{icon_svg}</span>
    <span style="font-weight: 600; color: {config['color']};">{title}</span>
  </section>
  <section class="admonition-content" style="padding: 12px 16px; background: {config['bg']}; border-left: 4px solid {config['color']};">
    <div style="font-size: 16px; color: #333; line-height: 1.6;">{body_html}</div>
  </section>
</section>'''

    return re.sub(r'```ad-(\w+)(?:[ \t]+title:[ \t]*(.*))?\n([\s\S]*?)```', repl, content)


def process_footnotes(content: str) -> str:
    """å°†é“¾æ¥è½¬æ¢ä¸ºè„šæ³¨å½¢å¼"""
    links = []

    def repl(m):
        text, url = m.group(1), m.group(2)
        links.append({'text': text, 'url': url})
        idx = len(links)
        return f'<span style="color: #3370ff;">{text}</span><sup style="color: #3370ff; font-weight: bold;">[{idx}]</sup>'

    content = re.sub(r'(?<!!)\[(.*?)\]\((.*?)\)', repl, content)

    if links:
        content += '\n\n<div class="footnotes">'
        content += '<h4 style="font-size: 14px; color: #999; margin-bottom: 12px; border-bottom: 1px solid #eee; padding-bottom: 5px;">å¼•ç”¨é“¾æ¥</h4>'
        for i, link in enumerate(links):
            content += f'<div class="footnote-item"><span style="color: #3370ff; font-weight: bold;">[{i+1}]</span> {link["text"]}: {link["url"]}</div>'
        content += '</div>'

    return content


def preprocess_markdown(body: str) -> str:
    """Markdown é¢„å¤„ç†ï¼šæ¸…ç†åˆ—è¡¨ç©ºè¡Œã€ä¿®å¤ä»£ç å—ç­‰"""
    # æ¸…ç†åˆ—è¡¨é¡¹é—´ç©ºè¡Œ
    body = re.sub(r'(\d+\.\s+[^\n]+)\n+(?=\s*\d+\.\s+)', r'\1\n', body)
    body = re.sub(r'([-*+]\s+[^\n]+)\n+(?=\s*[-*+]\s+)', r'\1\n', body)
    body = re.sub(r'\n{3,}', '\n\n', body)

    # ç¡®ä¿åˆ—è¡¨å‰æœ‰ç©ºè¡Œ
    body = _ensure_list_spacing(body)

    # ä¿®å¤åˆ—è¡¨å†…ä»£ç å—
    body = _fix_code_blocks_in_lists(body)

    # ç§»é™¤å­¤ç«‹è¯­è¨€æ ‡ç­¾
    body = re.sub(
        r'\n\s*(JSON|PYTHON|JAVASCRIPT|JAVA|SHELL|BASH|SQL|XML|HTML|CSS|YAML|TOML)\s*\n\s*\n(\s*```)',
        r'\n\n\2', body, flags=re.IGNORECASE
    )

    # é¢„å¤„ç† JSON æ³¨é‡Š
    body = _preprocess_json_comments(body)

    return body


def _ensure_list_spacing(content: str) -> str:
    """ç¡®ä¿åˆ—è¡¨å‰æœ‰ç©ºè¡Œ"""
    lines = content.split('\n')
    result = []

    for i, line in enumerate(lines):
        is_list_start = re.match(r'^(\s*)([-*+]|\d+\.)\s+', line)
        if is_list_start and i > 0:
            prev = lines[i - 1].strip()
            if (prev and
                not re.match(r'^([-*+]|\d+\.)\s+', prev) and
                not prev.startswith('#') and
                not prev.startswith('```') and
                not prev.startswith('>')):
                result.append('')
        result.append(line)

    return '\n'.join(result)


def _fix_code_blocks_in_lists(content: str) -> str:
    """ä¿®å¤åˆ—è¡¨é¡¹å†…ä»£ç å—çš„æ ¼å¼é—®é¢˜"""
    lines = content.split('\n')
    result = []
    i = 0

    while i < len(lines):
        line = lines[i]
        if re.match(r'^    ```\w*', line):
            code_block = [line.lstrip()]
            i += 1
            while i < len(lines):
                inner = lines[i]
                if re.match(r'^    ```\s*$', inner):
                    code_block.append('```')
                    i += 1
                    break
                code_block.append(re.sub(r'^    {1,2}', '', inner))
                i += 1
            result.extend([''] + code_block + [''])
        else:
            result.append(line)
            i += 1

    return '\n'.join(result)


def _preprocess_json_comments(content: str) -> str:
    """ç§»é™¤ JSON ä»£ç å—ä¸­çš„æ³¨é‡Š"""
    def process_block(match):
        lang, code = match.group(1), match.group(2)
        if lang.lower() == 'json':
            code = '\n'.join(re.sub(r'\s*//[^"]*$', '', line) for line in code.split('\n'))
        return f'```{lang}\n{code}```'

    return re.sub(r'```(\w+)\n([\s\S]*?)```', process_block, content)


# ================= HTML å¤„ç† =================

class WechatHTMLProcessor(HTMLParser):
    """å¾®ä¿¡å…¼å®¹çš„ HTML å¤„ç†å™¨"""

    def __init__(self):
        super().__init__()
        self.output = []
        self.list_stack = []
        self.in_pre = False
        self.in_li = False

    def handle_starttag(self, tag, attrs):
        attrs_dict = dict(attrs)

        if tag in ('ul', 'ol'):
            marker_type = 'num' if tag == 'ol' else 'bull'
            self.list_stack.append({'tag': tag, 'count': 1, 'marker_type': marker_type})
            self.output.append(self._build_tag(tag, self._inject_style(attrs, STYLES['list_container'])))
            return

        if tag == 'li':
            self.in_li = True
            self.output.append(self._build_tag(tag, self._inject_style(attrs, STYLES['list_item'])))
            if self.list_stack:
                current = self.list_stack[-1]
                level = len(self.list_stack) - 1
                if current['marker_type'] == 'num':
                    marker = f"{current['count']}. "
                    current['count'] += 1
                else:
                    marker = 'â—¦ ' if level % 2 == 1 else 'â€¢ '
                self.output.append(marker)
            return

        if tag == 'div' and 'highlight' in attrs_dict.get('class', '').split():
            self.output.append(self._build_tag(tag, self._inject_style(attrs, 'margin: 16px 0; padding: 0;')))
            return

        if tag == 'pre':
            self.in_pre = True
            self.output.append(self._build_tag(tag, self._inject_style(attrs, STYLES['pre'])))
            return

        if tag == 'code':
            if not self.in_pre and 'style' not in attrs_dict:
                self.output.append(self._build_tag(tag, self._inject_style(attrs, STYLES['inline_code'])))
            else:
                self.output.append(self._build_tag(tag, attrs))
            return

        if tag == 'p' and self.in_li:
            return

        self.output.append(self._build_tag(tag, attrs))

    def handle_endtag(self, tag):
        if tag in ('ul', 'ol') and self.list_stack:
            self.list_stack.pop()
        if tag == 'li':
            self.in_li = False
        if tag == 'pre':
            self.in_pre = False
        if tag == 'p' and self.in_li:
            self.output.append("<br>")
            return
        self.output.append(f"</{tag}>")

    def handle_data(self, data):
        self.output.append(data)

    def handle_entityref(self, name):
        self.output.append(f'&{name};')

    def handle_charref(self, name):
        self.output.append(f'&#{name};')

    def _build_tag(self, tag, attrs) -> str:
        if not attrs:
            return f"<{tag}>"
        if isinstance(attrs, list):
            attrs_str = " ".join(f'{k}="{v}"' for k, v in attrs)
        else:
            attrs_str = f'style="{attrs}"'
        return f"<{tag} {attrs_str}>"

    def _inject_style(self, attrs, style_to_add):
        new_attrs = dict(attrs)
        if 'style="' in style_to_add:
            match = re.search(r'style="([^"]*)"', style_to_add)
            style_to_add = match.group(1) if match else style_to_add

        current = new_attrs.get('style', '')
        if current and not current.strip().endswith(';'):
            current += ';'
        new_attrs['style'] = current + style_to_add
        return list(new_attrs.items())


def md_to_html(md_content: str) -> str:
    """Markdown è½¬ HTML"""
    html = markdown.markdown(
        md_content,
        extensions=['fenced_code', 'tables', 'codehilite'],
        extension_configs={
            'codehilite': {
                'css_class': 'highlight',
                'guess_lang': True,
                'use_pygments': True,
                'noclasses': True
            }
        }
    )

    final_html = f'''
    <section id="nice" style="background-color: #fffdf9; padding: 20px; border-radius: 8px;">
        {BASIC_STYLE}
        {html}
    </section>
    '''

    # åº”ç”¨æ ‡ç­¾æ ·å¼
    for tag in ['h1', 'h2', 'h3', 'h4', 'strong']:
        final_html = final_html.replace(f'<{tag}>', f'<{tag} style="{STYLES[tag]}">')

    final_html = final_html.replace('<th>', f'<th style="{STYLES["th"]}">')
    final_html = final_html.replace('<td>', f'<td style="{STYLES["td"]}">')
    final_html = re.sub(r'<hr\s*/?>', f'<hr style="{STYLES["hr"]}">', final_html)

    # ä½¿ç”¨ HTML å¤„ç†å™¨å¤„ç†åˆ—è¡¨å’Œä»£ç å—
    processor = WechatHTMLProcessor()
    processor.feed(final_html)
    final_html = "".join(processor.output)

    # åå¤„ç†
    final_html = _simplify_list_items(final_html)
    final_html = re.sub(r'</strong>\s*(<br\s*/?>)?\s*([ï¼š:])', r'\2</strong>', final_html)
    final_html = _convert_whitespace_in_code(final_html)
    final_html = _compress_html_preserve_pre(final_html)

    return final_html


def _simplify_list_items(html: str) -> str:
    """æ¸…ç†ç©ºåˆ—è¡¨é¡¹"""
    html = re.sub(r'<li[^>]*>\s*</li>', '', html)
    html = re.sub(r'<li[^>]*>\s*<p[^>]*>\s*</p>\s*</li>', '', html)
    html = re.sub(r'<p[^>]*>\s*</p>', '', html)
    html = re.sub(r'\n{3,}', '\n\n', html)
    return html


def _convert_whitespace_in_code(html: str) -> str:
    """å°†ä»£ç å—å†…ç©ºç™½è½¬æ¢ä¸º HTML å®ä½“"""
    def convert_text(text):
        if not text:
            return ''
        return text.replace('\t', '&nbsp;&nbsp;&nbsp;&nbsp;').replace(' ', '&nbsp;').replace('\n', '<br>')

    def process_pre_content(content):
        content = re.sub(r'<span style="color: #BBB">([^<]*)</span>', r'\1', content)
        result = []
        last_end = 0
        for m in re.finditer(r'<[^>]+>', content):
            result.append(convert_text(content[last_end:m.start()]))
            result.append(m.group(0))
            last_end = m.end()
        result.append(convert_text(content[last_end:]))
        return ''.join(result)

    return re.sub(
        r'(<pre[^>]*>)([\s\S]*?)</pre>',
        lambda m: f'{m.group(1)}{process_pre_content(m.group(2))}</pre>',
        html
    )


def _compress_html_preserve_pre(html: str) -> str:
    """å‹ç¼© HTML ä½†ä¿ç•™ pre å—å†…å®¹"""
    pre_blocks = []

    def save_pre(m):
        pre_blocks.append(m.group(0))
        return f'__PRE_PLACEHOLDER_{len(pre_blocks) - 1}__'

    html = re.sub(r'<pre[^>]*>[\s\S]*?</pre>', save_pre, html)
    html = re.sub(r'>\s+<', '><', html)

    for i, block in enumerate(pre_blocks):
        html = html.replace(f'__PRE_PLACEHOLDER_{i}__', block)

    return html


# ================= å·¥ä½œæµ =================

def process_content_workflow(content: str, token: str) -> tuple[dict, str]:
    """å®Œæ•´çš„ Markdown å¤„ç†å·¥ä½œæµ"""
    frontmatter = {}
    body = content

    match = re.match(r'^---\n(.*?)\n---\n', content, re.DOTALL)
    if match:
        frontmatter = yaml.safe_load(match.group(1))
        body = content[match.end():]

    body = preprocess_markdown(body)
    body = process_mermaid(body)

    # ä¸Šä¼ å›¾ç‰‡
    def replace_img(m):
        alt, src = m.group(1), m.group(2)
        print(f"æ­£åœ¨ä¸Šä¼ å›¾ç‰‡: {src}")
        wechat_url = upload_image(token, src)
        if not wechat_url:
            return m.group(0)

        is_mermaid = 'MERMAID_DIAGRAM' in alt or '/tmp' in src
        wrapper_class = 'mermaid-wrapper' if is_mermaid else 'image-wrapper'
        alt_text = 'æµç¨‹å›¾' if is_mermaid else alt
        shadow = '0 2px 8px rgba(0,0,0,0.1)' if is_mermaid else '0 2px 4px rgba(0,0,0,0.1)'

        return f'''
<section class="{wrapper_class}" style="text-align: center; margin: {'24' if is_mermaid else '20'}px 0;">
  <img src="{wechat_url}" alt="{alt_text}" style="max-width: 100%; height: auto; display: inline-block; border-radius: 4px; box-shadow: {shadow};" />
</section>'''

    body = re.sub(r'!\[(.*?)\]\((.*?)\)', replace_img, body)
    body = process_admonitions(body)
    body = process_footnotes(body)

    return frontmatter, body


def publish_draft(token: str, article_data: dict) -> dict:
    """å‘å¸ƒè‰ç¨¿åˆ°å¾®ä¿¡"""
    url = f"{WECHAT_API_BASE}/draft/add?access_token={token}"
    json_bytes = json.dumps(article_data, ensure_ascii=False).encode('utf-8')
    resp = requests.post(url, data=json_bytes, headers={'Content-Type': 'application/json; charset=utf-8'})
    return resp.json()


def main(file_path: str) -> None:
    print(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")

    try:
        config = load_config()
        token = get_access_token(config)
        print("Token è·å–æˆåŠŸ")
    except Exception as e:
        print(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    with open(file_path, 'r') as f:
        raw_content = f.read()

    print("æ­£åœ¨å¤„ç† Markdown å†…å®¹...")
    frontmatter, processed_body = process_content_workflow(raw_content, token)
    html_content = md_to_html(processed_body)

    thumb_media_id = frontmatter.get('thumb_media_id')

    # å°é¢è·å–ä¼˜å…ˆçº§ï¼š
    # 1. frontmatter ä¸­çš„ thumb_media_id
    # 2. frontmatter ä¸­çš„ banner/banner_pathï¼ˆç”¨æˆ·æä¾›å›¾ç‰‡ï¼‰
    # 3. Unsplash è‡ªåŠ¨æœç´¢
    # 4. é»˜è®¤å°é¢

    if not thumb_media_id:
        # å°è¯•ç”¨æˆ·æä¾›çš„ banner å›¾ç‰‡
        banner = frontmatter.get('banner')  # ç½‘ç»œ URL
        banner_path = frontmatter.get('banner_path')  # æœ¬åœ°è·¯å¾„

        if banner and banner.startswith(('http://', 'https://')):
            # ç½‘ç»œå›¾ç‰‡ï¼šå…ˆä¸‹è½½å†ä¸Šä¼ 
            print(f"æ­£åœ¨ä¸‹è½½ç”¨æˆ·å°é¢: {banner}")
            temp_path = download_image_to_temp(banner)
            if temp_path:
                print(f"æ­£åœ¨ä¸Šä¼ ç”¨æˆ·å°é¢...")
                thumb_media_id = upload_cover_material(token, temp_path)
                try:
                    os.unlink(temp_path)
                except:
                    pass
                if thumb_media_id:
                    print(f"  âœ“ å°é¢ä¸Šä¼ æˆåŠŸ: {thumb_media_id[:20]}...")
                else:
                    print(f"  å°é¢ä¸Šä¼ å¤±è´¥")
        elif banner_path:
            # æœ¬åœ°å›¾ç‰‡ï¼šç›´æ¥ä¸Šä¼ 
            print(f"æ­£åœ¨ä¸Šä¼ ç”¨æˆ·å°é¢: {banner_path}")
            thumb_media_id = upload_cover_material(token, banner_path)

    if not thumb_media_id:
        # å°è¯• Unsplash è‡ªåŠ¨æœç´¢
        title = frontmatter.get('title', "")
        digest = frontmatter.get('digest', "")
        thumb_media_id = get_auto_cover(config, token, title, digest)

    if not thumb_media_id:
        # ä½¿ç”¨é»˜è®¤å°é¢
        thumb_media_id = config.get('default_thumb_media_id')

    if not thumb_media_id:
        print("è­¦å‘Š: æœªæ‰¾åˆ°å°é¢å›¾ (thumb_media_id)")

    article = {
        "title": frontmatter.get('title', "æœªå‘½åæ–‡ç« "),
        "author": frontmatter.get('author', config.get('default_author')),
        "digest": frontmatter.get('digest', ""),
        "content": html_content,
        "content_source_url": frontmatter.get('source_url', ""),
        "thumb_media_id": thumb_media_id,
        "need_open_comment": frontmatter.get('open_comment', 0)
    }

    print("æ­£åœ¨å‘å¸ƒåˆ°è‰ç¨¿ç®±...")
    result = publish_draft(token, {"articles": [article]})
    print("å‘å¸ƒç»“æœ:", json.dumps(result, indent=2, ensure_ascii=False))

    if 'media_id' in result:
        print(f"\nâœ… å‘å¸ƒæˆåŠŸ! Media ID: {result['media_id']}")
    else:
        print("\nâŒ å‘å¸ƒå¤±è´¥")


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        main(sys.argv[1])
    else:
        print("è¯·æä¾› Markdown æ–‡ä»¶è·¯å¾„")
